import torch
import torchvision
import torchvision.transforms as transforms
from torchvision.datasets import ImageFolder
from torch._C import dtype

from torch.utils.data import DataLoader
from torch.utils.data import Dataset

import torchvision.datasets as dset

from functools import partial

import os
import zipfile

from natsort import natsorted
from PIL import Image

import matplotlib.pyplot as plt
import numpy as np

import csv
from collections import namedtuple
CSV = namedtuple("CSV", ["header", "index", "data"])

import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import copy

from numpy.random import default_rng
rng = default_rng()

import pandas as pd


!pip install --upgrade --no-cache-dir gdown
import gdown

!gdown --id 10lb95QoS1cy1GxYZQsLaxu6S-BTEeWSY


from datetime import datetime
from sklearn import metrics

######## Enabling GPU:
print(torch.cuda.device_count())
print(torch.cuda.get_device_name(0))
print(torch.cuda.is_available())

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
print(device)


####### Access to CelebA Dataset is Required ############
####### Two Options below for importing the data ########

######### Option#1 - Direct download from the wedsite: ####################3
# Root directory for the dataset
data_root = 'data/celeba'

# Path to download the dataset to
download_path = f'{data_root}/img_align_celeba.zip'

# Create required directories
if not os.path.exists(data_root):
  os.makedirs(data_root)
  #os.makedirs(dataset_folder)


with zipfile.ZipFile('/content/img_align_celeba_new1.zip', 'r') as ziphandler:
  #ziphandler.extractall(dataset_folder)
  ziphandler.extractall(data_root)

img_folder = f'{data_root}/img_align_celeba'
targets_folder = f'{data_root}/Targets'
if not os.path.exists(targets_folder):
  os.makedirs(targets_folder)

url ='https://drive.google.com/uc?id=1yMJD3R3nc7FkxkuChYZAOevL8kObW5hx'
download_path =f'{targets_folder}/list_attr_celeba.txt'
gdown.download(url, download_path, quiet=False)

#https://drive.google.com/file/d/1yMJD3R3nc7FkxkuChYZAOevL8kObW5hx/view?usp=drive_link


url ='https://drive.google.com/uc?id=1O3ffC2jZWgkhCQ3XL8ku3PaWDP48uQFH'
download_path =f'{targets_folder}/identity_CelebA.txt'
gdown.download(url, download_path, quiet=False)
######################################################################################################

## Option#2 - Download from your own Drive - If Option#1 fail: ##########################################################
"""
# Root directory for the dataset
data_root = 'data/celeba'

# Path to download the dataset to
download_path = f'{data_root}/img_align_celeba.zip'

# Create required directories
if not os.path.exists(data_root):
  os.makedirs(data_root)
  #os.makedirs(dataset_folder)



#with zipfile.ZipFile('/content/img_align_celeba_new1.zip', 'r') as ziphandler:
with zipfile.ZipFile('/content/drive/MyDrive/CelebA_Data/img_align_celeba_new3.zip', 'r') as ziphandler:
  #ziphandler.extractall(dataset_folder)
  ziphandler.extractall(data_root)

img_folder = f'{data_root}/img_align_celeba'
targets_folder = '/content/drive/MyDrive/CelebA_Utils'
"""
##############################################################################################################


################# Simulation:  ##############################################################################3
##General Setting:
batch_size = 20
N=202599
Nq=10000
IMG_WIDTH = 178
IMG_HEIGHT = 218

#Net Architecture:
C1= 32
C2= 64
C3=32
C4=16
Window_size=5
Poolong_size=2
P_Drop=0.5
H=100

#### Expiriment setting:
nqtr=100
nqte=900
nqtot=nqtr+nqte

H=300
tau0=1

Kf=  10 #num of folds
Samp_size1= 20   # Number of random  samples
Samp_size2= 200  #Wcv_Apprx main Loop
Samp_size4=1000  #Wcv_Apprx inner Loop

#Training:
Epochs=80 #100
EpochsB=8 #10
k2=Epochs #Val freq

## Create a custom Dataset class
class CelebADataset(Dataset):
  def __init__(self, root_dir, root_dir_Targets ,transform,N):
    self.root_dir = root_dir
    self.root_dir_Targets = root_dir_Targets
    self.transform = transform

    #landmarks_align = self._load_csv("list_landmarks_align_celeba.txt", header=1)
    Attr = self._load_csv("list_attr_celeba.txt", header=1)

    self.Smile = torch.maximum(Attr.data[0:N,31],torch.zeros(N))
    #self.NoseY = landmarks_align.data[0:N,5]
    self.image_names = Attr.index[0:N]

    Identities_file= self._load_csv("identity_CelebA.txt", header=None)
    self.Identities = Identities_file.data

    ### Building metaData for Identities
    Identities_Arr=self.Identities.numpy()
    Table=np.zeros((Identities_Arr.max(),40)).astype(int)
    for i in range(Table.shape[0]):
      Ident=i+1
      Table[i,0]=Ident
      ListOfindx=np.where(Identities_Arr==Ident)[0]
      L=len(ListOfindx)
      Table[i,1:L+1]=ListOfindx
      Table[i,39]=L

    self.MasterTable =Table


  def __len__(self):
    return len(self.image_names)


  def _load_csv(
        self,
        filename ,
        header ,
    ) -> CSV:
        data, indices, headers = [], [], []

        fn = partial(os.path.join, self.root_dir_Targets)
        with open(fn(filename)) as csv_file:
            data = list(csv.reader(csv_file, delimiter=' ', skipinitialspace=True))

        if header is not None:
            headers = data[header]
            data = data[header + 1:]

        indices = [row[0] for row in data]
        data = [row[1:] for row in data]
        data_int = [list(map(int, i)) for i in data]

        return CSV( headers, indices, torch.tensor(data_int) )


  def __getitem__(self, idx):
    # Get the path to the image
    img_path = os.path.join(self.root_dir, self.image_names[idx])
    # Load image and convert it to RGB
    img = Image.open(img_path).convert('RGB')
    # Apply transformations to the image
    if self.transform:
      img = self.transform(img)

    targrt=self.Smile[idx]

    return img,targrt
    #image_name=self.image_names[idx]
    #return img,targrt,image_name


  def __getIdentityItems__(self, Ident):
    nj=self.MasterTable[Ident-1,39]
    idxs=self.MasterTable[Ident-1,1:nj+1]
    imgs=torch.zeros( (nj ,3,IMG_HEIGHT,IMG_WIDTH) )
    targrts=torch.zeros( (nj ,1) )
    for j in range(nj):
      data=self.__getitem__(idxs[j])
      imgs[j,:,:,:]=data[0]
      targrts[j,0]=data[1]

    return imgs,targrts

  def __getItemsByIndices__(self, idxs):
    nj=len(idxs)
    imgs=torch.zeros( (nj ,3,IMG_HEIGHT,IMG_WIDTH) )
    targrts=torch.zeros( (nj ,1) )
    for j in range(nj):
      data=self.__getitem__(idxs[j])
      imgs[j,:,:,:]=data[0]
      targrts[j,0]=data[1]

    return imgs,targrts

class Net(nn.Module):
    def __init__(self ,input_shape=(3,IMG_HEIGHT, IMG_WIDTH)):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(3, C1, Window_size)
        self.conv2 = nn.Conv2d(C1, C2, Window_size)
        self.conv3 = nn.Conv2d(C2, C3, Window_size)
        self.conv4 = nn.Conv2d(C3, C4, Window_size)
        self.pool = nn.MaxPool2d(Poolong_size, Poolong_size)

        n_size = self._get_conv_output(input_shape)

        self.fc1 = nn.Linear(n_size, H)
        self.fc2 = nn.Linear(H, 1)

        self.dropout = nn.Dropout(P_Drop)


    def _get_conv_output(self, shape):
      input = torch.autograd.Variable(torch.rand(10, *shape))
      output_feat = self._forward_features(input)
      n_size = output_feat.size(1)
      return n_size

    def _forward_features(self, x):
      x = self.pool(F.relu(self.conv1(x)))
      x = self.pool(F.relu(self.conv2(x)))
      x = self.pool(F.relu(self.conv3(x)))
      x = self.pool(F.relu(self.conv4(x)))
      x = torch.flatten(x, 1)
      return x


    def forward(self, x):
        x = self._forward_features(x)
        x=self.dropout(x)
        x = F.leaky_relu(self.fc1(x))
        x = self.fc2(x)
        return x

    def Semi_forward(self, x):

        x = self._forward_features(x)
        x = F.leaky_relu(self.fc1(x))
        return x

## Load the dataset
transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])
celeba_dataset = CelebADataset(img_folder,targets_folder, transform,N)
Totloader  = torch.utils.data.DataLoader(celeba_dataset, batch_size=10, num_workers=2, shuffle=True)
Master_Identities_Table=celeba_dataset.MasterTable
Nq=Master_Identities_Table.shape[0]

def FromFTableTo_Splited_IdentitiesTable_k(Fnum):
  startindx=Fnum*Fsize
  if Fnum<Kf-1:
    endindx=startindx+Fsize
  if Fnum==Kf-1:
    endindx=ntr

  va_id=np.arange(startindx,endindx)
  F_Table_cv=F_Table[va_id,:]
  F_Table_tr=np.delete(F_Table, va_id, axis=0)
  Identities_Table_tr_k=np.zeros((nqtr,40)).astype(int)
  Identities_Table_cv_k=np.zeros((nqtr,40)).astype(int)
  Identities_Table_tr_k[:,0]=Identities_Table_tr[:,0]
  Identities_Table_cv_k[:,0]=Identities_Table_tr[:,0]

  for j in range(nqtr):
    Ident=Identities_Table_tr[j,0]
    ListOfindx=F_Table_tr[np.where(F_Table_tr[:,0]==Ident)[0],1]
    L=len(ListOfindx)
    Identities_Table_tr_k[j,1:L+1]=ListOfindx
    Identities_Table_tr_k[j,39]=L

    ListOfindx=F_Table_cv[np.where(F_Table_cv[:,0]==Ident)[0],1]
    L=len(ListOfindx)
    Identities_Table_cv_k[j,1:L+1]=ListOfindx
    Identities_Table_cv_k[j,39]=L

  return Identities_Table_tr_k, Identities_Table_cv_k, F_Table_cv



def g(z):
    return 1/(1+np.exp(-z)) ## Zigmoid

def g_inv(z):
    return np.log(z/(1-z)) ##Zigmoid_inv

def g_tag(z):
    return np.exp(-z)/(1+np.exp(-z))**2 ## Zigmoid-tag

def G(z):
    return np.log(1+np.exp(z)) ## Zigmoid Prime




